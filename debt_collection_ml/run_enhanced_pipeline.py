#!/usr/bin/env python3\n\"\"\"\nEnhanced ML Pipeline for Debt Collection System\nIntegrates advanced feature engineering, hyperparameter optimization, and MLflow tracking\n\"\"\"\n\nimport sys\nimport os\nimport pandas as pd\nimport numpy as np\nfrom pathlib import Path\nimport logging\nfrom datetime import datetime\nimport warnings\nimport json\nwarnings.filterwarnings('ignore')\n\n# Add src to path\nsys.path.append('src')\n\n# Import modules\nfrom data.data_generator import DebtCollectionDataGenerator\nfrom data.data_preprocessor import AdvancedDataPreprocessor\nfrom features.enhanced_feature_engineering import EnhancedFeatureEngineer\nfrom models.enhanced_model_trainer import EnhancedModelTrainer\nfrom mlops.mlflow_integration import MLflowModelTracker\n\n# Setup logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(levelname)s - %(message)s',\n    handlers=[\n        logging.FileHandler('enhanced_pipeline.log'),\n        logging.StreamHandler()\n    ]\n)\nlogger = logging.getLogger(__name__)\n\nclass EnhancedMLPipeline:\n    \"\"\"Enhanced ML Pipeline with advanced features and MLOps integration\"\"\"\n    \n    def __init__(self, config: dict = None):\n        self.config = config or self._get_default_config()\n        self.results = {}\n        self.artifacts = {}\n        \n        # Initialize MLflow tracker\n        self.mlflow_tracker = MLflowModelTracker(\"debt_collection_enhanced\")\n        \n        logger.info(\"Enhanced ML Pipeline initialized\")\n    \n    def _get_default_config(self) -> dict:\n        \"\"\"Get default configuration\"\"\"\n        return {\n            # Data generation\n            'data': {\n                'n_samples': 10000,\n                'random_state': 42\n            },\n            \n            # Preprocessing\n            'preprocessing': {\n                'imputation_strategy': 'knn',\n                'scaling_method': 'standard',\n                'encoding_method': 'onehot',\n                'handle_outliers': True,\n                'outlier_method': 'iqr'\n            },\n            \n            # Enhanced feature engineering\n            'feature_engineering': {\n                'include_time_series': True,\n                'include_financial_ratios': True,\n                'include_behavioral_features': True,\n                'include_polynomial': False,  # Disabled to prevent feature explosion\n                'feature_selection': True,\n                'selection_k': 50,\n                'selection_method': 'f_classif'\n            },\n            \n            # Enhanced model training\n            'training': {\n                'optimize_hyperparameters': True,\n                'n_trials': 50,  # Increased for better optimization\n                'cv_folds': 5,\n                'test_size': 0.2,\n                'random_state': 42,\n                'class_balance_method': 'smote',\n                'target_metric': 'f1_weighted'\n            },\n            \n            # MLflow configuration\n            'mlflow': {\n                'experiment_name': 'debt_collection_enhanced',\n                'track_experiments': True,\n                'register_best_model': True\n            }\n        }\n    \n    def create_directories(self):\n        \"\"\"Create necessary directories\"\"\"\n        directories = [\n            'data/raw', 'data/processed', 'models/trained', \n            'models/artifacts', 'models/enhanced', 'reports', \n            'logs', 'mlruns', 'experiments'\n        ]\n        \n        for directory in directories:\n            Path(directory).mkdir(parents=True, exist_ok=True)\n        \n        logger.info(\"Enhanced directory structure created\")\n    \n    def generate_data(self) -> pd.DataFrame:\n        \"\"\"Generate synthetic dataset\"\"\"\n        logger.info(f\"Generating {self.config['data']['n_samples']} samples...\")\n        \n        generator = DebtCollectionDataGenerator(\n            n_samples=self.config['data']['n_samples'],\n            random_state=self.config['data']['random_state']\n        )\n        df = generator.generate_dataset()\n        \n        # Save raw data\n        df.to_csv('data/raw/debt_collection_data_enhanced.csv', index=False)\n        \n        logger.info(f\"Generated enhanced dataset with {len(df)} samples\")\n        logger.info(f\"Outcome distribution:\\n{df['Outcome'].value_counts()}\")\n        \n        return df\n    \n    def preprocess_data(self, df: pd.DataFrame) -> tuple:\n        \"\"\"Preprocess the data with advanced techniques\"\"\"\n        logger.info(\"Starting advanced data preprocessing...\")\n        \n        # Initialize preprocessor with config\n        preprocessor = AdvancedDataPreprocessor(**self.config['preprocessing'])\n        \n        # Fit and transform\n        X_processed, y_encoded = preprocessor.fit_transform(df, target_column='Outcome')\n        \n        # Save processed data\n        np.save('data/processed/X_processed_enhanced.npy', X_processed)\n        np.save('data/processed/y_encoded_enhanced.npy', y_encoded)\n        \n        # Save preprocessor\n        preprocessor.save_preprocessor('models/artifacts/preprocessor_enhanced.joblib')\n        \n        logger.info(f\"Advanced preprocessing completed. Shape: {X_processed.shape}\")\n        \n        return X_processed, y_encoded, preprocessor\n    \n    def engineer_features(self, X_processed: np.ndarray, y_encoded: np.ndarray, \n                         preprocessor) -> tuple:\n        \"\"\"Apply enhanced feature engineering\"\"\"\n        logger.info(\"Starting enhanced feature engineering...\")\n        \n        # Convert to DataFrame using feature names from preprocessor\n        feature_df = pd.DataFrame(X_processed, columns=preprocessor.feature_names)\n        \n        # Initialize enhanced feature engineer\n        feature_engineer = EnhancedFeatureEngineer(**self.config['feature_engineering'])\n        \n        # Apply feature engineering\n        X_engineered = feature_engineer.fit_transform(feature_df, y_encoded)\n        \n        # Save engineered features\n        np.save('data/processed/X_engineered_enhanced.npy', X_engineered)\n        \n        # Save feature engineer\n        feature_engineer.save_feature_engineer('models/artifacts/feature_engineer_enhanced.joblib')\n        \n        # Get feature importance analysis\n        feature_analysis = feature_engineer.get_feature_importance_analysis()\n        \n        # Save feature analysis\n        with open('reports/feature_analysis_enhanced.json', 'w') as f:\n            json.dump(feature_analysis, f, indent=2)\n        \n        logger.info(f\"Enhanced feature engineering completed. Shape: {X_engineered.shape}\")\n        logger.info(f\"Feature engineering methods used: {feature_analysis['feature_engineering_methods']}\")\n        \n        return X_engineered, feature_engineer, feature_analysis\n    \n    def train_models(self, X_engineered: np.ndarray, y_encoded: np.ndarray) -> dict:\n        \"\"\"Train models with enhanced techniques and optimization\"\"\"\n        logger.info(\"Starting enhanced model training with optimization...\")\n        \n        # Initialize enhanced model trainer\n        trainer = EnhancedModelTrainer(**self.config['training'])\n        \n        # Train models\n        training_results = trainer.train_models(X_engineered, y_encoded)\n        \n        # Save training results\n        trainer.save_training_results('models/artifacts/training_results_enhanced.joblib')\n        \n        # Get optimization summary\n        optimization_summary = trainer.get_optimization_summary()\n        \n        # Save optimization results\n        with open('reports/optimization_summary_enhanced.json', 'w') as f:\n            json.dump(optimization_summary, f, indent=2, default=str)\n        \n        logger.info(f\"Enhanced model training completed\")\n        logger.info(f\"Best model: {training_results['best_model']}\")\n        logger.info(f\"Best F1 score: {max(training_results['results'][k]['f1_weighted'] for k in training_results['results'].keys()):.4f}\")\n        \n        return training_results, trainer, optimization_summary\n    \n    def track_with_mlflow(self, \n                         training_results: dict,\n                         feature_analysis: dict,\n                         optimization_summary: dict,\n                         X_train: np.ndarray,\n                         y_train: np.ndarray,\n                         X_test: np.ndarray,\n                         y_test: np.ndarray) -> str:\n        \"\"\"Track experiment with MLflow\"\"\"\n        \n        if not self.config['mlflow']['track_experiments']:\n            logger.info(\"MLflow tracking disabled\")\n            return None\n        \n        logger.info(\"Tracking experiment with MLflow...\")\n        \n        try:\n            # Prepare training configuration for MLflow\n            training_config = {\n                **self.config['data'],\n                **self.config['preprocessing'],\n                **self.config['feature_engineering'],\n                **self.config['training']\n            }\n            \n            # Track training session\n            run_id = self.mlflow_tracker.track_training_session(\n                models=training_results['models'],\n                model_results=training_results['results'],\n                training_config=training_config,\n                X_train=X_train,\n                y_train=y_train,\n                X_test=X_test,\n                y_test=y_test,\n                optimization_studies=optimization_summary if optimization_summary else None\n            )\n            \n            logger.info(f\"MLflow tracking completed. Run ID: {run_id}\")\n            return run_id\n            \n        except Exception as e:\n            logger.error(f\"MLflow tracking failed: {e}\")\n            return None\n    \n    def generate_enhanced_report(self, \n                               df: pd.DataFrame,\n                               training_results: dict,\n                               feature_analysis: dict,\n                               optimization_summary: dict,\n                               mlflow_run_id: str = None) -> str:\n        \"\"\"Generate comprehensive enhanced report\"\"\"\n        logger.info(\"Generating enhanced comprehensive report...\")\n        \n        # Find best model\n        best_model_name = training_results['best_model']\n        best_results = training_results['results'][best_model_name]\n        \n        # Build enhanced report\n        report_lines = [\n            \"ENHANCED DEBT COLLECTION ML PIPELINE REPORT\",\n            \"=\" * 60,\n            \"\",\n            f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\",\n            f\"MLflow Run ID: {mlflow_run_id or 'Not tracked'}\",\n            \"\",\n            \"DATASET OVERVIEW:\",\n            f\"- Total samples: {len(df):,}\",\n            f\"- Original features: {feature_analysis.get('original_feature_count', 'N/A')}\",\n            f\"- Engineered features: {feature_analysis.get('final_feature_count', 'N/A')}\",\n            f\"- Feature engineering methods: {', '.join(feature_analysis.get('feature_engineering_methods', []))}\",\n            \"\",\n            \"TARGET DISTRIBUTION:\",\n            df['Outcome'].value_counts().to_string(),\n            \"\",\n            \"ENHANCED MODEL PERFORMANCE:\",\n            \"-\" * 40\n        ]\n        \n        # Add model results with enhanced metrics\n        for name, metrics in training_results['results'].items():\n            report_lines.extend([\n                \"\",\n                f\"{name}:\",\n                f\"  - Accuracy: {metrics['accuracy']:.4f}\",\n                f\"  - F1-Score (Weighted): {metrics['f1_weighted']:.4f}\",\n                f\"  - F1-Score (Macro): {metrics['f1_macro']:.4f}\",\n                f\"  - F1-Score (Micro): {metrics.get('f1_micro', 'N/A'):.4f}\",\n                f\"  - Precision (Weighted): {metrics.get('precision_weighted', 'N/A'):.4f}\",\n                f\"  - Recall (Weighted): {metrics.get('recall_weighted', 'N/A'):.4f}\",\n                f\"  - ROC-AUC: {metrics['roc_auc']:.4f}\",\n                f\"  - Business F1: {metrics['business_f1']:.4f}\"\n            ])\n            \n            # Add class-wise F1 scores if available\n            if 'class_f1_scores' in metrics:\n                class_scores = metrics['class_f1_scores']\n                for i, score in enumerate(class_scores):\n                    report_lines.append(f\"  - Class {i} F1: {score:.4f}\")\n        \n        # Add optimization summary\n        if optimization_summary:\n            report_lines.extend([\n                \"\",\n                \"HYPERPARAMETER OPTIMIZATION SUMMARY:\",\n                \"-\" * 40\n            ])\n            \n            for model_name, opt_data in optimization_summary.items():\n                report_lines.extend([\n                    \"\",\n                    f\"{model_name} Optimization:\",\n                    f\"  - Best CV Score: {opt_data.get('best_score', 'N/A'):.4f}\",\n                    f\"  - Trials Completed: {opt_data.get('n_trials', 'N/A')}\",\n                    f\"  - Best Parameters: {opt_data.get('best_params', {})}\"\n                ])\n        \n        # Add performance comparison with baseline\n        baseline_f1 = 0.41  # From previous results\n        improvement = best_results['f1_weighted'] - baseline_f1\n        improvement_pct = (improvement / baseline_f1) * 100\n        \n        report_lines.extend([\n            \"\",\n            \"PERFORMANCE IMPROVEMENT:\",\n            \"-\" * 30,\n            f\"Baseline F1 Score: {baseline_f1:.4f}\",\n            f\"Enhanced F1 Score: {best_results['f1_weighted']:.4f}\",\n            f\"Absolute Improvement: {improvement:.4f}\",\n            f\"Relative Improvement: {improvement_pct:.1f}%\",\n            \"\",\n            f\"TARGET ACHIEVEMENT: {'‚úÖ ACHIEVED' if best_results['f1_weighted'] >= 0.65 else '‚ùå NOT YET ACHIEVED'} (Target: 0.65)\"\n        ])\n        \n        # Add files generated\n        report_lines.extend([\n            \"\",\n            \"ENHANCED FILES GENERATED:\",\n            \"- data/raw/debt_collection_data_enhanced.csv\",\n            \"- data/processed/X_processed_enhanced.npy\",\n            \"- data/processed/X_engineered_enhanced.npy\",\n            \"- data/processed/y_encoded_enhanced.npy\",\n            \"- models/artifacts/preprocessor_enhanced.joblib\",\n            \"- models/artifacts/feature_engineer_enhanced.joblib\",\n            \"- models/artifacts/training_results_enhanced.joblib\",\n            \"- models/trained/*_optimized.joblib\",\n            \"- reports/feature_analysis_enhanced.json\",\n            \"- reports/optimization_summary_enhanced.json\",\n            \"\",\n            \"NEXT STEPS:\",\n            \"1. Deploy the best model using MLflow model registry\",\n            \"2. Set up monitoring and drift detection\",\n            \"3. Implement A/B testing framework\",\n            \"4. Create web interface for predictions\",\n            \"5. Set up automated retraining pipeline\",\n            \"\",\n            \"=\" * 60\n        ])\n        \n        # Join all lines into final report\n        report = \"\\n\".join(report_lines)\n        \n        # Save report\n        with open('reports/enhanced_pipeline_report.txt', 'w') as f:\n            f.write(report)\n        \n        print(report)\n        \n        return report\n    \n    def run_complete_pipeline(self) -> dict:\n        \"\"\"Run the complete enhanced pipeline\"\"\"\n        \n        print(\"üöÄ Starting Enhanced Debt Collection ML Pipeline...\")\n        print(\"=\" * 70)\n        \n        try:\n            # Step 1: Setup\n            self.create_directories()\n            \n            # Step 2: Generate data\n            df = self.generate_data()\n            \n            # Step 3: Preprocess data\n            X_processed, y_encoded, preprocessor = self.preprocess_data(df)\n            \n            # Step 4: Engineer features\n            X_engineered, feature_engineer, feature_analysis = self.engineer_features(\n                X_processed, y_encoded, preprocessor\n            )\n            \n            # Step 5: Train models with optimization\n            training_results, trainer, optimization_summary = self.train_models(\n                X_engineered, y_encoded\n            )\n            \n            # Step 6: Track with MLflow\n            mlflow_run_id = self.track_with_mlflow(\n                training_results=training_results,\n                feature_analysis=feature_analysis,\n                optimization_summary=optimization_summary,\n                X_train=X_engineered,  # Using full engineered features for tracking\n                y_train=y_encoded,\n                X_test=training_results['X_test'],\n                y_test=training_results['y_test']\n            )\n            \n            # Step 7: Generate enhanced report\n            report = self.generate_enhanced_report(\n                df=df,\n                training_results=training_results,\n                feature_analysis=feature_analysis,\n                optimization_summary=optimization_summary,\n                mlflow_run_id=mlflow_run_id\n            )\n            \n            # Save results summary\n            best_model_name = training_results['best_model']\n            best_f1 = training_results['results'][best_model_name]['f1_weighted']\n            \n            summary = {\n                'timestamp': datetime.now().isoformat(),\n                'dataset_size': len(df),\n                'models_trained': len(training_results['models']),\n                'best_model': best_model_name,\n                'best_f1_score': float(best_f1),\n                'target_achieved': bool(best_f1 >= 0.65),\n                'improvement_over_baseline': float(best_f1 - 0.41),\n                'mlflow_run_id': mlflow_run_id,\n                'feature_engineering_methods': feature_analysis.get('feature_engineering_methods', []),\n                'hyperparameter_optimization': bool(self.config['training']['optimize_hyperparameters']),\n                'model_results': {\n                    k: {\n                        'accuracy': float(v['accuracy']),\n                        'f1_weighted': float(v['f1_weighted']),\n                        'f1_macro': float(v['f1_macro']),\n                        'roc_auc': float(v['roc_auc']),\n                        'business_f1': float(v['business_f1'])\n                    } for k, v in training_results['results'].items()\n                }\n            }\n            \n            with open('reports/enhanced_results_summary.json', 'w') as f:\n                json.dump(summary, f, indent=2)\n            \n            print(\"\\n‚úÖ Enhanced Pipeline completed successfully!\")\n            print(f\"üìä Best model: {best_model_name}\")\n            print(f\"üéØ F1 Score: {best_f1:.4f} (Target: 0.65)\")\n            print(f\"üìà Improvement: {(best_f1 - 0.41):.4f} over baseline\")\n            print(f\"üéØ Target {'ACHIEVED' if best_f1 >= 0.65 else 'NOT YET ACHIEVED'}\")\n            print(\"üìÅ Check reports/enhanced_pipeline_report.txt for detailed results\")\n            \n            if mlflow_run_id:\n                print(f\"üî¨ MLflow Run ID: {mlflow_run_id}\")\n            \n            return summary\n            \n        except Exception as e:\n            logger.error(f\"Enhanced pipeline failed: {e}\")\n            print(f\"‚ùå Enhanced pipeline failed: {e}\")\n            raise\n\ndef main():\n    \"\"\"Main pipeline execution\"\"\"\n    \n    # You can customize the configuration here\n    custom_config = {\n        'data': {\n            'n_samples': 15000,  # Increased sample size\n            'random_state': 42\n        },\n        'training': {\n            'optimize_hyperparameters': True,\n            'n_trials': 100,  # More trials for better optimization\n            'cv_folds': 5,\n            'test_size': 0.2,\n            'random_state': 42,\n            'class_balance_method': 'smote',\n            'target_metric': 'f1_weighted'\n        }\n    }\n    \n    # Initialize and run pipeline\n    pipeline = EnhancedMLPipeline(custom_config)\n    results = pipeline.run_complete_pipeline()\n    \n    return results\n\nif __name__ == \"__main__\":\n    results = main()\n    sys.exit(0)