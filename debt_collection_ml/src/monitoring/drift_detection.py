import pandas as pd\nimport numpy as np\nfrom evidently import ColumnMapping\nfrom evidently.report import Report\nfrom evidently.metric_preset import DataDriftPreset, TargetDriftPreset, DataQualityPreset\nfrom evidently.metrics import *\nfrom evidently.test_suite import TestSuite\nfrom evidently.tests import *\nimport json\nimport logging\nfrom typing import Dict, Any, List, Optional, Tuple\nfrom datetime import datetime, timedelta\nfrom pathlib import Path\nimport joblib\nfrom scipy import stats\nimport warnings\nwarnings.filterwarnings('ignore')\n\nlogger = logging.getLogger(__name__)\n\nclass DataDriftDetector:\n    \"\"\"Data drift detection using Evidently AI and statistical tests\"\"\"\n    \n    def __init__(self, \n                 reference_data: Optional[pd.DataFrame] = None,\n                 feature_columns: Optional[List[str]] = None,\n                 target_column: Optional[str] = None,\n                 drift_threshold: float = 0.1,\n                 statistical_test: str = 'ks'):\n        \n        self.reference_data = reference_data\n        self.feature_columns = feature_columns\n        self.target_column = target_column\n        self.drift_threshold = drift_threshold\n        self.statistical_test = statistical_test\n        \n        # Drift detection results\n        self.drift_results = {}\n        self.drift_history = []\n        \n        # Column mapping for Evidently\n        self.column_mapping = None\n        if feature_columns and target_column:\n            self.column_mapping = ColumnMapping(\n                numerical_features=feature_columns,\n                target=target_column\n            )\n        \n        self.logger = logging.getLogger(__name__)\n        self.logger.info(\"Data drift detector initialized\")\n    \n    def set_reference_data(self, reference_data: pd.DataFrame, \n                          feature_columns: List[str], \n                          target_column: str = None):\n        \"\"\"Set reference data for drift detection\"\"\"\n        \n        self.reference_data = reference_data.copy()\n        self.feature_columns = feature_columns\n        self.target_column = target_column\n        \n        # Update column mapping\n        self.column_mapping = ColumnMapping(\n            numerical_features=feature_columns,\n            target=target_column if target_column else None\n        )\n        \n        self.logger.info(f\"Reference data set with {len(reference_data)} samples and {len(feature_columns)} features\")\n    \n    def detect_feature_drift(self, current_data: pd.DataFrame) -> Dict[str, Any]:\n        \"\"\"Detect feature drift using Evidently AI\"\"\"\n        \n        if self.reference_data is None:\n            raise ValueError(\"Reference data not set. Use set_reference_data() first.\")\n        \n        self.logger.info(\"Detecting feature drift...\")\n        \n        try:\n            # Create data drift report\n            data_drift_report = Report(metrics=[\n                DataDriftPreset()\n            ])\n            \n            # Run the report\n            data_drift_report.run(\n                reference_data=self.reference_data,\n                current_data=current_data,\n                column_mapping=self.column_mapping\n            )\n            \n            # Get results as dictionary\n            drift_results = data_drift_report.as_dict()\n            \n            # Extract key metrics\n            drift_summary = {\n                'timestamp': datetime.now().isoformat(),\n                'dataset_drift': drift_results['metrics'][0]['result']['dataset_drift'],\n                'drift_share': drift_results['metrics'][0]['result']['drift_share'],\n                'number_of_drifted_columns': drift_results['metrics'][0]['result']['number_of_drifted_columns'],\n                'drifted_features': [],\n                'feature_drift_scores': {}\n            }\n            \n            # Extract per-feature drift information\n            if 'drift_by_columns' in drift_results['metrics'][0]['result']:\n                drift_by_columns = drift_results['metrics'][0]['result']['drift_by_columns']\n                \n                for feature, drift_info in drift_by_columns.items():\n                    if isinstance(drift_info, dict):\n                        drift_summary['feature_drift_scores'][feature] = {\n                            'drift_detected': drift_info.get('drift_detected', False),\n                            'drift_score': drift_info.get('drift_score', 0.0),\n                            'threshold': drift_info.get('threshold', self.drift_threshold)\n                        }\n                        \n                        if drift_info.get('drift_detected', False):\n                            drift_summary['drifted_features'].append(feature)\n            \n            self.drift_results['feature_drift'] = drift_summary\n            self.logger.info(f\"Feature drift detection completed. Drift detected: {drift_summary['dataset_drift']}\")\n            \n            return drift_summary\n            \n        except Exception as e:\n            self.logger.error(f\"Feature drift detection failed: {e}\")\n            return {'error': str(e), 'timestamp': datetime.now().isoformat()}\n    \n    def detect_target_drift(self, current_data: pd.DataFrame) -> Dict[str, Any]:\n        \"\"\"Detect target drift using Evidently AI\"\"\"\n        \n        if self.reference_data is None or self.target_column is None:\n            raise ValueError(\"Reference data and target column must be set for target drift detection\")\n        \n        if self.target_column not in current_data.columns:\n            self.logger.warning(f\"Target column '{self.target_column}' not found in current data\")\n            return {'error': 'Target column not found', 'timestamp': datetime.now().isoformat()}\n        \n        self.logger.info(\"Detecting target drift...\")\n        \n        try:\n            # Create target drift report\n            target_drift_report = Report(metrics=[\n                TargetDriftPreset()\n            ])\n            \n            # Run the report\n            target_drift_report.run(\n                reference_data=self.reference_data,\n                current_data=current_data,\n                column_mapping=self.column_mapping\n            )\n            \n            # Get results as dictionary\n            drift_results = target_drift_report.as_dict()\n            \n            # Extract key metrics\n            target_drift_summary = {\n                'timestamp': datetime.now().isoformat(),\n                'target_drift_detected': False,\n                'target_drift_score': 0.0,\n                'target_distribution_change': {}\n            }\n            \n            # Extract target drift information\n            if len(drift_results['metrics']) > 0:\n                target_metrics = drift_results['metrics'][0]['result']\n                \n                if 'drift_detected' in target_metrics:\n                    target_drift_summary['target_drift_detected'] = target_metrics['drift_detected']\n                \n                if 'drift_score' in target_metrics:\n                    target_drift_summary['target_drift_score'] = target_metrics['drift_score']\n            \n            self.drift_results['target_drift'] = target_drift_summary\n            self.logger.info(f\"Target drift detection completed. Drift detected: {target_drift_summary['target_drift_detected']}\")\n            \n            return target_drift_summary\n            \n        except Exception as e:\n            self.logger.error(f\"Target drift detection failed: {e}\")\n            return {'error': str(e), 'timestamp': datetime.now().isoformat()}\n    \n    def detect_data_quality_issues(self, current_data: pd.DataFrame) -> Dict[str, Any]:\n        \"\"\"Detect data quality issues using Evidently AI\"\"\"\n        \n        if self.reference_data is None:\n            raise ValueError(\"Reference data not set. Use set_reference_data() first.\")\n        \n        self.logger.info(\"Detecting data quality issues...\")\n        \n        try:\n            # Create data quality report\n            data_quality_report = Report(metrics=[\n                DataQualityPreset()\n            ])\n            \n            # Run the report\n            data_quality_report.run(\n                reference_data=self.reference_data,\n                current_data=current_data,\n                column_mapping=self.column_mapping\n            )\n            \n            # Get results as dictionary\n            quality_results = data_quality_report.as_dict()\n            \n            # Extract key quality metrics\n            quality_summary = {\n                'timestamp': datetime.now().isoformat(),\n                'missing_values': {},\n                'data_types_changed': [],\n                'new_columns': [],\n                'missing_columns': [],\n                'quality_score': 1.0\n            }\n            \n            # Process quality metrics\n            if len(quality_results['metrics']) > 0:\n                for metric in quality_results['metrics']:\n                    metric_result = metric.get('result', {})\n                    \n                    # Extract missing values information\n                    if 'current' in metric_result and 'missing_count' in str(metric_result):\n                        # This is a simplified extraction - actual structure may vary\n                        pass\n            \n            self.drift_results['data_quality'] = quality_summary\n            self.logger.info(\"Data quality detection completed\")\n            \n            return quality_summary\n            \n        except Exception as e:\n            self.logger.error(f\"Data quality detection failed: {e}\")\n            return {'error': str(e), 'timestamp': datetime.now().isoformat()}\n    \n    def statistical_drift_test(self, \n                              reference_feature: np.ndarray, \n                              current_feature: np.ndarray,\n                              test_type: str = 'ks') -> Dict[str, float]:\n        \"\"\"Perform statistical drift test on individual features\"\"\"\n        \n        try:\n            if test_type == 'ks':\n                # Kolmogorov-Smirnov test\n                statistic, p_value = stats.ks_2samp(reference_feature, current_feature)\n            elif test_type == 'chi2':\n                # Chi-square test (for categorical data)\n                # Create bins for continuous data\n                bins = np.histogram_bin_edges(np.concatenate([reference_feature, current_feature]), bins=10)\n                ref_hist, _ = np.histogram(reference_feature, bins=bins)\n                cur_hist, _ = np.histogram(current_feature, bins=bins)\n                \n                # Avoid zero frequencies\n                ref_hist = ref_hist + 1\n                cur_hist = cur_hist + 1\n                \n                statistic, p_value = stats.chisquare(cur_hist, ref_hist)\n            elif test_type == 'mannwhitney':\n                # Mann-Whitney U test\n                statistic, p_value = stats.mannwhitneyu(reference_feature, current_feature, alternative='two-sided')\n            else:\n                raise ValueError(f\"Unknown test type: {test_type}\")\n            \n            drift_detected = p_value < self.drift_threshold\n            \n            return {\n                'statistic': float(statistic),\n                'p_value': float(p_value),\n                'drift_detected': drift_detected,\n                'test_type': test_type\n            }\n            \n        except Exception as e:\n            self.logger.error(f\"Statistical drift test failed: {e}\")\n            return {\n                'statistic': 0.0,\n                'p_value': 1.0,\n                'drift_detected': False,\n                'test_type': test_type,\n                'error': str(e)\n            }\n    \n    def comprehensive_drift_analysis(self, current_data: pd.DataFrame) -> Dict[str, Any]:\n        \"\"\"Perform comprehensive drift analysis\"\"\"\n        \n        self.logger.info(\"Starting comprehensive drift analysis...\")\n        \n        analysis_results = {\n            'timestamp': datetime.now().isoformat(),\n            'analysis_type': 'comprehensive',\n            'data_shape': {\n                'reference': self.reference_data.shape if self.reference_data is not None else None,\n                'current': current_data.shape\n            }\n        }\n        \n        # 1. Feature drift detection\n        try:\n            feature_drift = self.detect_feature_drift(current_data)\n            analysis_results['feature_drift'] = feature_drift\n        except Exception as e:\n            self.logger.error(f\"Feature drift analysis failed: {e}\")\n            analysis_results['feature_drift'] = {'error': str(e)}\n        \n        # 2. Target drift detection (if target column available)\n        if self.target_column and self.target_column in current_data.columns:\n            try:\n                target_drift = self.detect_target_drift(current_data)\n                analysis_results['target_drift'] = target_drift\n            except Exception as e:\n                self.logger.error(f\"Target drift analysis failed: {e}\")\n                analysis_results['target_drift'] = {'error': str(e)}\n        \n        # 3. Data quality analysis\n        try:\n            data_quality = self.detect_data_quality_issues(current_data)\n            analysis_results['data_quality'] = data_quality\n        except Exception as e:\n            self.logger.error(f\"Data quality analysis failed: {e}\")\n            analysis_results['data_quality'] = {'error': str(e)}\n        \n        # 4. Statistical tests for each feature\n        if self.feature_columns and self.reference_data is not None:\n            statistical_results = {}\n            \n            for feature in self.feature_columns:\n                if feature in current_data.columns and feature in self.reference_data.columns:\n                    try:\n                        ref_values = self.reference_data[feature].dropna().values\n                        cur_values = current_data[feature].dropna().values\n                        \n                        if len(ref_values) > 0 and len(cur_values) > 0:\n                            stat_result = self.statistical_drift_test(\n                                ref_values, cur_values, self.statistical_test\n                            )\n                            statistical_results[feature] = stat_result\n                    except Exception as e:\n                        self.logger.warning(f\"Statistical test failed for feature {feature}: {e}\")\n                        statistical_results[feature] = {'error': str(e)}\n            \n            analysis_results['statistical_tests'] = statistical_results\n        \n        # 5. Overall drift summary\n        drift_summary = self._create_drift_summary(analysis_results)\n        analysis_results['summary'] = drift_summary\n        \n        # Store results\n        self.drift_history.append(analysis_results)\n        \n        self.logger.info(f\"Comprehensive drift analysis completed. Overall drift detected: {drift_summary['overall_drift_detected']}\")\n        \n        return analysis_results\n    \n    def _create_drift_summary(self, analysis_results: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Create overall drift summary from analysis results\"\"\"\n        \n        summary = {\n            'overall_drift_detected': False,\n            'drift_severity': 'low',\n            'drifted_features_count': 0,\n            'total_features_analyzed': 0,\n            'drift_percentage': 0.0,\n            'recommendations': []\n        }\n        \n        # Analyze feature drift\n        if 'feature_drift' in analysis_results and 'drifted_features' in analysis_results['feature_drift']:\n            drifted_features = analysis_results['feature_drift']['drifted_features']\n            summary['drifted_features_count'] = len(drifted_features)\n            \n            if self.feature_columns:\n                summary['total_features_analyzed'] = len(self.feature_columns)\n                summary['drift_percentage'] = (len(drifted_features) / len(self.feature_columns)) * 100\n        \n        # Analyze statistical tests\n        if 'statistical_tests' in analysis_results:\n            stat_drifted = sum(1 for result in analysis_results['statistical_tests'].values() \n                             if isinstance(result, dict) and result.get('drift_detected', False))\n            summary['statistical_drift_count'] = stat_drifted\n        \n        # Determine overall drift\n        if summary['drift_percentage'] > 20:  # More than 20% of features drifted\n            summary['overall_drift_detected'] = True\n            summary['drift_severity'] = 'high'\n        elif summary['drift_percentage'] > 10:  # 10-20% of features drifted\n            summary['overall_drift_detected'] = True\n            summary['drift_severity'] = 'medium'\n        elif summary['drift_percentage'] > 5:  # 5-10% of features drifted\n            summary['overall_drift_detected'] = True\n            summary['drift_severity'] = 'low'\n        \n        # Generate recommendations\n        if summary['overall_drift_detected']:\n            if summary['drift_severity'] == 'high':\n                summary['recommendations'].extend([\n                    \"Immediate model retraining recommended\",\n                    \"Investigate data collection process\",\n                    \"Consider feature engineering updates\"\n                ])\n            elif summary['drift_severity'] == 'medium':\n                summary['recommendations'].extend([\n                    \"Schedule model retraining within 1-2 weeks\",\n                    \"Monitor model performance closely\",\n                    \"Analyze drifted features for patterns\"\n                ])\n            else:\n                summary['recommendations'].extend([\n                    \"Continue monitoring\",\n                    \"Consider retraining if performance degrades\"\n                ])\n        else:\n            summary['recommendations'].append(\"No immediate action required\")\n        \n        return summary\n    \n    def save_drift_report(self, analysis_results: Dict[str, Any], filepath: str):\n        \"\"\"Save drift analysis report to file\"\"\"\n        \n        try:\n            with open(filepath, 'w') as f:\n                json.dump(analysis_results, f, indent=2, default=str)\n            \n            self.logger.info(f\"Drift report saved to {filepath}\")\n            \n        except Exception as e:\n            self.logger.error(f\"Failed to save drift report: {e}\")\n    \n    def load_drift_history(self, filepath: str):\n        \"\"\"Load drift history from file\"\"\"\n        \n        try:\n            with open(filepath, 'r') as f:\n                self.drift_history = json.load(f)\n            \n            self.logger.info(f\"Drift history loaded from {filepath}\")\n            \n        except Exception as e:\n            self.logger.error(f\"Failed to load drift history: {e}\")\n    \n    def save_drift_history(self, filepath: str):\n        \"\"\"Save drift history to file\"\"\"\n        \n        try:\n            with open(filepath, 'w') as f:\n                json.dump(self.drift_history, f, indent=2, default=str)\n            \n            self.logger.info(f\"Drift history saved to {filepath}\")\n            \n        except Exception as e:\n            self.logger.error(f\"Failed to save drift history: {e}\")\n    \n    def get_drift_trends(self, days: int = 30) -> Dict[str, Any]:\n        \"\"\"Analyze drift trends over time\"\"\"\n        \n        if not self.drift_history:\n            return {'error': 'No drift history available'}\n        \n        # Filter recent history\n        cutoff_date = datetime.now() - timedelta(days=days)\n        recent_history = [\n            result for result in self.drift_history\n            if datetime.fromisoformat(result['timestamp']) > cutoff_date\n        ]\n        \n        if not recent_history:\n            return {'error': f'No drift history in the last {days} days'}\n        \n        # Analyze trends\n        trends = {\n            'period_days': days,\n            'total_analyses': len(recent_history),\n            'drift_detected_count': 0,\n            'average_drift_percentage': 0.0,\n            'trend_direction': 'stable',\n            'most_drifted_features': {}\n        }\n        \n        drift_percentages = []\n        feature_drift_counts = {}\n        \n        for result in recent_history:\n            if 'summary' in result and 'overall_drift_detected' in result['summary']:\n                if result['summary']['overall_drift_detected']:\n                    trends['drift_detected_count'] += 1\n                \n                drift_pct = result['summary'].get('drift_percentage', 0.0)\n                drift_percentages.append(drift_pct)\n                \n                # Count feature drifts\n                if 'feature_drift' in result and 'drifted_features' in result['feature_drift']:\n                    for feature in result['feature_drift']['drifted_features']:\n                        feature_drift_counts[feature] = feature_drift_counts.get(feature, 0) + 1\n        \n        if drift_percentages:\n            trends['average_drift_percentage'] = np.mean(drift_percentages)\n            \n            # Determine trend direction\n            if len(drift_percentages) >= 3:\n                recent_avg = np.mean(drift_percentages[-3:])\n                earlier_avg = np.mean(drift_percentages[:-3]) if len(drift_percentages) > 3 else drift_percentages[0]\n                \n                if recent_avg > earlier_avg * 1.2:\n                    trends['trend_direction'] = 'increasing'\n                elif recent_avg < earlier_avg * 0.8:\n                    trends['trend_direction'] = 'decreasing'\n        \n        # Most frequently drifted features\n        if feature_drift_counts:\n            sorted_features = sorted(feature_drift_counts.items(), key=lambda x: x[1], reverse=True)\n            trends['most_drifted_features'] = dict(sorted_features[:10])  # Top 10\n        \n        return trends\n\nif __name__ == \"__main__\":\n    # Test drift detection\n    import pandas as pd\n    import numpy as np\n    \n    # Create sample reference data\n    np.random.seed(42)\n    reference_data = pd.DataFrame({\n        'feature_1': np.random.normal(0, 1, 1000),\n        'feature_2': np.random.normal(5, 2, 1000),\n        'feature_3': np.random.exponential(1, 1000),\n        'target': np.random.randint(0, 3, 1000)\n    })\n    \n    # Create sample current data with some drift\n    current_data = pd.DataFrame({\n        'feature_1': np.random.normal(0.5, 1.2, 800),  # Slight drift\n        'feature_2': np.random.normal(5, 2, 800),      # No drift\n        'feature_3': np.random.exponential(1.5, 800),  # Moderate drift\n        'target': np.random.randint(0, 3, 800)\n    })\n    \n    # Test drift detector\n    detector = DataDriftDetector()\n    detector.set_reference_data(\n        reference_data=reference_data,\n        feature_columns=['feature_1', 'feature_2', 'feature_3'],\n        target_column='target'\n    )\n    \n    # Run comprehensive analysis\n    results = detector.comprehensive_drift_analysis(current_data)\n    \n    print(f\"Drift detected: {results['summary']['overall_drift_detected']}\")\n    print(f\"Drift severity: {results['summary']['drift_severity']}\")\n    print(f\"Drifted features: {results['summary']['drifted_features_count']}/{results['summary']['total_features_analyzed']}\")\n    print(\"Drift detection test completed!\")